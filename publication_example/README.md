Producing the example from the publication
=========

The following is a detailed description of how to reproduce [this example](https://chemrxiv.org/engage/chemrxiv/article-details/647060d7be16ad5c57f1ab9a). This will assume you have installed the files using 

~~~~
bash -i install.sh
~~~~

Additionally, we recommend you to first look at the workflow example in `../small_sample_run.sh`.

Running Lib-INVENT
-----------------

Settings available for the example run is available in `libInventSettings.json`.

While in <path to project directory>/Lib-INVENT run
~~~
python path_to_lib_invent_/input.py libInventSettings.json
~~~
This will not perfectly reproduce the same output, as some GPU-utilizing functions of pytorch, such as NLLLoss does not support random seeds.

### NOTE: You need to update the settings file with file paths to your own repository
The generated example for the publication here is  `libINVENT_output.csv`
The generated file will be processed by  `../readLibInventOutput.py` to extract building block SMILES from the synthons generated by LibINVENT to be parsed in AiZynthFinder. Note that for pontentially finding shorter routes, we presume that the Buchwald-Hartwig building blocks can be available with different halogens, and as such query AiZynthFinder with Cl, Br and I, implemented in `../readLibInventOutput.py`. This creates multiple building blocks that map to the same synthons, which have to be considered downstream. The example files provided in this repository uses only Cl, to avoid these duplicates (but `../optimizeLibrary.py` is made to work even if they exist).

The output is run through the AiZynthfinder  with the configs available at `aizynth_config.yml`. 

The snapshot of eMolecules used as stock is not available at stockfile.hdf5
### NOTE: You need to update the config file with file paths to your own repository
### NOTE2: You neeed to use the environment provided by aizynth-env.yml
### NOTE3: We stronly encourage you to split the smiles file in `../readLibInventOutput.py` as is default before performing an analysis of 5 minutes per building block (among building blocks not in stock).
AiZynthFinder was then run using the command

~~~
aizynthcli --config aizynth_config.yml --smiles <smiles_file>  --output example_output
~~~

The outputs can be parsed by `../aggregateAizynthFinderOutput.py`, but is also provided by `AC_full.csv` and `BH_full.csv`. We can now finally use `../main.py` with the default settings to optimize a library selection. This will read the building block .csv files and map them to synthons using the dictionaries generated by  `../readLibInventOutput.py` to create the products during runtime of `../optimizeLibrary.py`. This script was run in batch array using [SLURM](https://slurm.schedmd.com/overview.html), varying the `index` from 0-4 to initialize the algorithm with different seeds.

TODO: Clean the post-processing and output analysis scripts for producing statistics across multiple runs.
